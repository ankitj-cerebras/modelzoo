train_input:
    batch_size: 768
    data_processor: GptHDF5MapDataProcessor
    micro_batch_size: 12
    data_dir: "./language/datasets/SlimPajama/train_shuffled_msl8192/"
    num_workers: 1
    persistent_workers: true
    prefetch_factor: 10
    shuffle: false
    shuffle_seed: 1
    vocab_size: 84992
eval_input:
    batch_size: 32
    data_dir: "./language/datasets/SlimPajama/val_msl8192/"
    data_processor: GptHDF5MapDataProcessor
    num_workers: 1
    shuffle: false
    vocab_size: 84992
model:
    attention_dropout_rate: 0.0
    attention_kernel: optimized_beta
    attention_type: scaled_dot_product
    boundary_casting: false
    dropout_rate: 0.0
    embedding_initializer:
        a: -0.146
        b: 0.146
        mean: 0.0
        name: truncated_normal
        std: 0.073
    embeddings_scale: 14.6
    filter_size: 19114
    fp16_type: cbfloat16
    hidden_size: 7168
    initializer:
        a: -0.027591406529673585
        b: 0.027591406529673585
        mean: 0.0
        name: truncated_normal
        std: 0.013795703264836793
    layer_norm_epsilon: 1.0e-05
    loss_scaling: batch_size
    loss_weight: 0.0001220703125
    max_position_embeddings: 8192
    mixed_precision: true
    nonlinearity: swiglu
    num_heads: 56
    num_hidden_layers: 48
    output_layer_initializer:
        a: -0.0028160361368081773
        b: 0.0028160361368081773
        mean: 0.0
        name: truncated_normal
        std: 0.0014080180684040886
    output_logits_scale: 0.07928571428571429
    position_embedding_type: alibi
    scale_qk_dot_by_d: true
    share_embedding_weights: true
    use_bias_in_output: false
    use_ffn_bias: true
    use_ffn_bias_in_attention: true
    use_projection_bias_in_attention: true
    vocab_size: 84992
optimizer:
    adjust_learning_rate:
        decoder_kernel: 0.03571428571428571
    betas:
    - 0.9
    - 0.95
    correct_bias: true
    eps: 8.0e-10
    learning_rate:
    -   end_learning_rate: 0.00048
        initial_learning_rate: 0.00156280142255127
        scheduler: Linear
        total_iters: 70719
    log_summaries: true
    max_gradient_norm: 1.0
    optimizer_type: AdamW
    weight_decay: 0.1
    loss_scaling_factor: dynamic
runconfig:
    checkpoint_steps: 500
    log_steps: 1
    max_steps: 260648
    precision_opt_level: 1
    save_initial_checkpoint: false
    seed: 1
