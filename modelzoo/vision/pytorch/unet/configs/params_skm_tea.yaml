# Params for UNet model on SKM-TEA dataset.

train_input: &train_input
    data_processor: SkmDataProcessor
    data_dir: "./computer_vision/datasets/skm-tea_hdf/skm-tea-160x512x512/v1-release"
    echo_type: "echo1"  # {"echo1", "echo2", "echo1-echo2-mc", "root_sum_of_squares"}
    aggregate_cartilage: True
    image_shape: [160, 512, 512] # (D, H, W)
    normalize_data_method: "standard_score"
    shuffle: True
    shuffle_seed: 1234
    # The effective batch size, which is evenly divided across "num_csx" systems used for the run
    batch_size: 1
    num_classes: 5
    num_workers: 2
    prefetch_factor: 10
    persistent_workers: True
    use_worker_cache: True

eval_input:
    <<: *train_input
    augment_data: False
    shuffle: False
    # The effective batch size, which is evenly divided across "num_csx" systems used for the run
    batch_size: 1
    num_workers: 1

model:
    nonlinearity: "relu"
    norm_layer: "group_instance"
    use_conv3d: True
    skip_connect: True
    enable_bias: False
    downscale_method: "strided_conv"
    convs_per_block: ["3x3_conv", "3x3_conv"]
    input_channels: 1
    encoder_filters: [32, 64, 128, 256]
    decoder_filters: [128, 64, 32]
    downscale_first_conv: True
    downscale_encoder_blocks: [False, True, True]
    downscale_bottleneck: True
    residual_blocks: False
    initializer:
        "name": "glorot_uniform"
        "gain": 1.0
    bias_initializer: "zeros"
    loss: "ssce_dice"
    mixed_precision: True
    eval_ignore_classes: [0] # void classes to ignore in evaluation
    eval_metrics: ["DSC"]
    use_bfloat16: True

optimizer:
    optimizer_type: "AdamW"
    weight_decay: 0.0
    learning_rate:
        initial_learning_rate: 5.0e-4
        scheduler: "PiecewiseConstant"
        milestones: [10000]
        learning_rates: [5.0e-4, 1.0e-5]
    # Choices: `loss_scaling_factor`: {"dynamic", use values >= 1.0 for static loss scaling}
    # Note: When `use_bfloat16: True`, this always defaults to `1.0`
    loss_scaling_factor: "dynamic"

runconfig:
    max_steps: 10000
    log_steps: 1
    checkpoint_steps: 1000
    seed: 1
    save_initial_checkpoint: True
    num_csx: 1
    num_act_servers: 1
    num_wgt_servers: 1
    num_workers_per_csx: 1
    compile_crd_memory_gi: 90
    wrk_memory_gi: -1
