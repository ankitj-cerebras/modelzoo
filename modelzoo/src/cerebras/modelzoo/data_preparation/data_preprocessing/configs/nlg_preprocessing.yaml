##############################################################
## Customized NLG Dataset Preprocessing Parameters
##############################################################

setup:
    data:
        source: "/input/dir/here" 
        type: local

    mode: "nlg"
    output_dir: "/output/dir/here" # replace with your directory
    processes: 1

processing:
    custom_tokenizer: "gpt2tokenizer"
    tokenizer_params:
        vocab_file: "/path/to/vocab"
        encoder_file: "/path/to/encoder"

    max_seq_length: 1024
    write_in_batch: True
    resume_from_checkpoint: False
    read_hook: "cerebras.modelzoo.data_preparation.data_preprocessing.hooks:nlg_read_hook"
    read_hook_kwargs:
        context_key: "context"
        completion_key: "completion"
    
    shuffle_seed: 0
    shuffle: False
    use_ftfy: True
    UNSAFE_skip_jsonl_decoding_errors: False
    